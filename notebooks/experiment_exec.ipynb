{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments on Community Detection in RecSys\n",
    "\n",
    "This Jupyter notebook aims to conduct a series of experiments to evaluate how the performance of specific recommendation algorithms varies with the addition of community detectors. The experiments will be performed using the MovieLens 100k and Jester datasets. The scikit-surprise library will also be used.\n",
    "\n",
    "The main goal of these experiments is to verify whether the integration of community detection techniques in recommender systems can improve the recommendation accuracy. The algorithms will be evaluated based on RMSE, MSE and MAE metrics and the results will be saved in CSV format for further analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Importing needed libs\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Importing needed libs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from surprise import (\n",
    "    accuracy,\n",
    "    Reader,\n",
    "    Dataset,\n",
    "    CoClustering,\n",
    "    KNNBasic,\n",
    "    NMF,\n",
    "    SVD\n",
    ")\n",
    "from surprise.model_selection.split import ShuffleSplit\n",
    "from surprise.trainset import Trainset\n",
    "import networkx as nx\n",
    "from cdlib import algorithms \n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Setting up functions\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Setting up functions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncouple(train_set: Trainset, test_set: list):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        It takes in a Trainset object and a list \n",
    "        of test set data, and returns two pandas \n",
    "        dataframes: one containing the training set \n",
    "        data, and the other containing the test set \n",
    "        data.\n",
    "    Input: \n",
    "        train_set: a Trainset object containing the \n",
    "        training set data. \n",
    "        test_set: a list containing the test set data\n",
    "    Output:\n",
    "        df_train: a pandas dataframe containing the \n",
    "        training set data, with columns 'uid', 'iid' \n",
    "        and 'rating'\n",
    "        df_test: a pandas dataframe containing the test \n",
    "        set data, with columns 'uid', 'iid', and 'rating'\n",
    "    \"\"\"\n",
    "    iterator = train_set.all_ratings()\n",
    "    df_train = pd.DataFrame(columns=['uid','iid','rating'])\n",
    "    i=0\n",
    "    for (uid, iid, rating) in iterator:\n",
    "        df_train.loc[i] = [uid, iid, rating]\n",
    "        i=i+1\n",
    "    df_test = pd.DataFrame.from_records(test_set, columns = ['uid', 'iid', 'rating'])\n",
    "    \n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "\n",
    "def get_similarity_matrix(data: pd.DataFrame, index: List[str], columns: List[str], values: str, metric: str):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        It takes the ratings data and returns an\n",
    "        user-user similarity matrix.\n",
    "        Null data is filled with zero.\n",
    "    Input: \n",
    "        data: pandas DataFrame containing the data \n",
    "        to be transformed into a rating matrix\n",
    "        index: a list of strings representing the \n",
    "        column names that will be used as the index \n",
    "        columns: a list of strings representing the \n",
    "        column names that will be used as the columns \n",
    "        of the rating matrix.\n",
    "        values: a string representing the column name \n",
    "        metric: the metric to use when calculating \n",
    "        distance between instances\n",
    "    Output:\n",
    "        similarity_matrix: an pandas user-user similarity\n",
    "        matrix\n",
    "    \"\"\"\n",
    "    if metric not in ['cosine', 'euclidian', 'l1', 'l2']:\n",
    "        raise ValueError('Invalid metric. Please choose one of the following: cosine, euclidian, l1 or l2')\n",
    "    rating_matrix = data.pivot_table(index=index, columns=columns, values=values)\n",
    "    rating_matrix = rating_matrix.copy().fillna(0)\n",
    "    similarity_matrix = pairwise_distances(rating_matrix, rating_matrix, metric=metric)\n",
    "    \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Setting up experiment algorithms \\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Setting up experiment algorithms \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "algos_recommendation = {\n",
    "    'SVD': SVD(),\n",
    "    'k-NN': KNNBasic(), \n",
    "    'NMF': NMF(), \n",
    "    'Co-Clustering': CoClustering()\n",
    "}\n",
    "\n",
    "communities_detectors = {\n",
    "    'Not-Applicable': None,\n",
    "    'Louvain': algorithms.louvain,\n",
    "    'Paris': algorithms.paris,\n",
    "    'Surprise': algorithms.surprise_communities \n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for dataset in tqdm(['ml-100k', 'jester'], desc='General Progress', leave=True):\n",
    "    data = Dataset.load_builtin(dataset)\n",
    "    for similarity_metric in  tqdm(['cosine', 'euclidian', 'l1', 'l2'], desc='Similarity Metric Progress', leave=False): \n",
    "        for detector_name, community_detector in tqdm(communities_detectors.items(), desc='Community Detector Progress', leave=False):\n",
    "            for algo_name, algo in  tqdm(algos_recommendation.items(), desc='Algorithm Progress', leave=False):\n",
    "                for test_size in tqdm([0.25, 0.1, 0.01], desc='Test Size Progress', leave=False):\n",
    "                    shuffle_split = ShuffleSplit(n_splits=100, test_size=test_size)\n",
    "                    split_id = 1\n",
    "                    for trainset, testset in shuffle_split.split(data):\n",
    "                        if community_detector != None:\n",
    "                        #-------------------\n",
    "                            trainpd, testpd = uncouple(trainset, testset)\n",
    "                            similarity_matrix = get_similarity_matrix(trainpd, index=['uid'], columns=['iid'], \n",
    "                                                                    values='rating', metric=similarity_metric)\n",
    "                            G = nx.from_numpy_matrix(similarity_matrix)\n",
    "                            for u, v in G.edges():\n",
    "                                similarity = similarity_matrix[u][v]\n",
    "                                G[u][v]['weight'] = similarity\n",
    "                            coms = community_detector(G)\n",
    "                            \n",
    "                            all_predictions = []\n",
    "                            for community in coms.communities:\n",
    "                                train_community = trainpd[trainpd['uid'].isin(community)]\n",
    "                                test_community = testpd[testpd['uid'].isin(community)]\n",
    "                                \n",
    "                                reader = Reader(rating_scale=(1, 5))\n",
    "                                train_surprise = Dataset.load_from_df(train_community[['uid', 'iid', 'rating']], \n",
    "                                                                      reader)\n",
    "                                train_surprise = train_surprise.build_full_trainset()\n",
    "                                test_surprise = list(test_community.itertuples(index=False, name=None))\n",
    "                                \n",
    "                                algo.fit(train_surprise)\n",
    "                                predictions = algo.test(test_surprise)\n",
    "                                all_predictions.extend(predictions)\n",
    "                            rmse_value = accuracy.rmse(all_predictions, verbose=False)\n",
    "                            mse_value = accuracy.mse(all_predictions, verbose=False)\n",
    "                            mae_value = accuracy.mae(all_predictions, verbose=False)\n",
    "                        #--------------------\n",
    "                        else:\n",
    "                            algo.fit(trainset)\n",
    "                            predictions = algo.test(testset)\n",
    "                        rmse_value = accuracy.rmse(predictions, verbose=False)\n",
    "                        mse_value = accuracy.mse(predictions, verbose=False)\n",
    "                        mae_value = accuracy.mae(predictions, verbose=False)\n",
    "                        result_dict = {\n",
    "                            'dataset': dataset,\n",
    "                            'similarity_metric': similarity_metric,\n",
    "                            'community_detector': detector_name,\n",
    "                            'algorithm_rec': algo_name,\n",
    "                            'test_size': test_size,\n",
    "                            'split_id': split_id,\n",
    "                            'rmse': rmse_value,\n",
    "                            'mse': mse_value,\n",
    "                            'mae': mae_value\n",
    "                        }\n",
    "                        results.append(result_dict)\n",
    "                        split_id += 1\n",
    "\n",
    "\n",
    "# Saving results as .csv file\n",
    "df_results = pd.DataFrame(results)\n",
    "file_name = 'results.csv'\n",
    "notebook_dir = os.getcwd()\n",
    "outputs_dir = notebook_dir.replace('notebooks', 'outputs')\n",
    "file_path = os.path.join(outputs_dir, file_name)\n",
    "df_results.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mscenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9af17dd3974b7d3f07030b1611a67048f1f5084e02d6dc9f5527477bb4d7d2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
