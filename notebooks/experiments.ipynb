{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments on Community Detection in RecSys\n",
    "\n",
    "This Jupyter notebook aims to conduct a series of experiments to evaluate how the performance of specific recommendation algorithms varies with the addition of community detectors. The experiments will be performed using the MovieLens 100k and Jester datasets. The scikit-surprise library will also be used.\n",
    "\n",
    "The main goal of these experiments is to verify whether the integration of community detection techniques in recommender systems can improve the recommendation accuracy. The algorithms will be evaluated based on RMSE, MSE and MAE metrics and the results will be saved in CSV format for further analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Importing needed libs\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Importing needed libs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from surprise import (\n",
    "    accuracy,\n",
    "    Reader,\n",
    "    Dataset,\n",
    "    CoClustering,\n",
    "    KNNBasic,\n",
    "    NMF,\n",
    "    SVD\n",
    ")\n",
    "from surprise.model_selection.split import ShuffleSplit\n",
    "from surprise.trainset import Trainset\n",
    "import networkx as nx\n",
    "from cdlib import algorithms \n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Setting up functions\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Setting up functions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncouple(train_set: Trainset, test_set: list):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        It takes in a Trainset-Surprise object and \n",
    "        a list of test set data, and returns two pandas \n",
    "        dataframes: one containing the training set \n",
    "        data, and the other containing the test set \n",
    "        data.\n",
    "    Input: \n",
    "        train_set: a Trainset object containing the \n",
    "        training set data. \n",
    "        test_set: a list containing the test set data\n",
    "    Output:\n",
    "        df_train: a pandas dataframe containing the \n",
    "        training set data, with columns 'uid', 'iid' \n",
    "        and 'rating'\n",
    "        df_test: a pandas dataframe containing the test \n",
    "        set data, with columns 'uid', 'iid', and 'rating'\n",
    "    \"\"\"\n",
    "    iterator = train_set.all_ratings()\n",
    "    df_train = pd.DataFrame(train_set.all_ratings(), columns=['uid', 'iid', 'rating'])\n",
    "    df_test = pd.DataFrame.from_records(test_set, columns = ['uid', 'iid', 'rating'])\n",
    "    \n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "\n",
    "def get_similarity_matrix(data: pd.DataFrame, index: List[str], columns: List[str], values: str, metric: str):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        It takes the ratings data and returns an\n",
    "        user-user similarity matrix.\n",
    "        Null data is filled with zero.\n",
    "    Input: \n",
    "        data: pandas DataFrame containing the data \n",
    "        to be transformed into a rating matrix\n",
    "        index: a list of strings representing the \n",
    "        column names that will be used as the index \n",
    "        columns: a list of strings representing the \n",
    "        column names that will be used as the columns \n",
    "        of the rating matrix.\n",
    "        values: a string representing the column name \n",
    "        metric: the metric to use when calculating \n",
    "        distance between instances\n",
    "    Output:\n",
    "        similarity_matrix: an pandas user-user similarity\n",
    "        matrix\n",
    "    \"\"\"\n",
    "    if metric not in ['cosine', 'euclidean', 'l1', 'l2']:\n",
    "        raise ValueError('Invalid metric. Please choose one of the following: cosine, euclidean, l1 or l2')\n",
    "    rating_matrix = data.pivot_table(index=index, columns=columns, values=values)\n",
    "    rating_matrix = rating_matrix.copy().fillna(0)\n",
    "    similarity_matrix = pairwise_distances(rating_matrix, rating_matrix, metric=metric)\n",
    "    \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Setting up experiment algorithms \\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Setting up experiment algorithms \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "algos_recommendation = {\n",
    "    'SVD': SVD(),\n",
    "    'k-NN': KNNBasic(), \n",
    "    'NMF': NMF(), \n",
    "    'Co-Clustering': CoClustering()\n",
    "}\n",
    "\n",
    "communities_detectors = {\n",
    "    'Not-Applicable': None,\n",
    "    'Louvain': algorithms.louvain,\n",
    "    'Paris': algorithms.paris,\n",
    "    'Surprise': algorithms.surprise_communities \n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ed65d6a38640e58c5997fa78716364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "General Progress:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b0678acc624fd59251cdbf18ad31f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Size Progress:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a600657e51f64eef9ac3cdd978e38337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Splits Progress: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed548c118e5465493e5cdbcfe67c064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Similarity Metric Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc07d02b8bc34f9aa6f46ab9a9242d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Community Detector Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec36fbfbcb04df996463bbcc961755f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29878e0fe88342b1a0946a2a92ba8bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800244bccd2149618e01cece2af70574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6d0b1e1ace409780308ad9036ade80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a205cbe4844b4e268e2f53c3caaf7d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Community Detector Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48bfc84a14194120b815c71ee02d5cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a4f7ef3869b4bed8179a70e1a737f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e8be41147a4551a22d2f81ce2f51c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8fbf5d4f99493d8af6932554d8ddf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1badb626f749b8b0e9bdea3c545b41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Community Detector Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc42dc07a7643d09ff9c36eac13bb1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0c270cacf349788c5b26fd94a129fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c82cbbacf64ef7b0fb418637b5e8da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8ceb57599f4ffc9855aeefdea1ee5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee86ec77e6ee4726890db0a393da271c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Community Detector Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990f47b277814014b1e8a2c7ded1e26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17dd799bf3ea4e81bf547361f3ca0771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba37ed463014f3fa3a033dc43c47e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256bc2f213384a41a1b3d2caca3cf41d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d63d64608d44dea9a1312a4ce79cd3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Similarity Metric Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0992b4d6da4c918477763f078d0829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Community Detector Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c22f8cb4fd54218ae160b72a2f8ff4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144b33d9ce7f4af9a36defd5c4fe8be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e9c256f3a74da4a4ac2df6947890cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5828b6c6bdc74ff5a7f4a2f62fc63772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035a08b76c2a4e8c83f19630dac67e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Community Detector Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f535976887d344f5aec3e35f8c75aa91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f41628baaf8a4d22ac910d25d05fec39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7bd89a2fd53422c9eb6b27528fcf40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3cf3ae87b1c45a4aa3f233d1013318e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41dc0a8d9b87416f839eb1531701a3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Community Detector Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323749693c5d4108a75496ed1e0e43e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a75cd01eb7648039b974ddb90644181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73111eec78394e8ba5215a103fb27c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f19357954b9413a968a0b9811d2e7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m trainpd, testpd \u001b[39m=\u001b[39m uncouple(trainset, testset)\n\u001b[0;32m     14\u001b[0m similarity_matrix \u001b[39m=\u001b[39m get_similarity_matrix(trainpd, index\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39muid\u001b[39m\u001b[39m'\u001b[39m], columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39miid\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[0;32m     15\u001b[0m                                         values\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m, metric\u001b[39m=\u001b[39msimilarity_metric)\n\u001b[1;32m---> 16\u001b[0m G \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39;49mfrom_numpy_matrix(similarity_matrix)\n\u001b[0;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m u, v \u001b[39min\u001b[39;00m G\u001b[39m.\u001b[39medges():\n\u001b[0;32m     18\u001b[0m     similarity \u001b[39m=\u001b[39m similarity_matrix[u][v]\n",
      "File \u001b[1;32mc:\\Users\\rdutr\\anaconda3\\envs\\mscenv\\lib\\site-packages\\networkx\\convert_matrix.py:694\u001b[0m, in \u001b[0;36mfrom_numpy_matrix\u001b[1;34m(A, parallel_edges, create_using)\u001b[0m\n\u001b[0;32m    603\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns a graph from numpy matrix.\u001b[39;00m\n\u001b[0;32m    604\u001b[0m \n\u001b[0;32m    605\u001b[0m \u001b[39mThe numpy matrix is interpreted as an adjacency matrix for the graph.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    685\u001b[0m \n\u001b[0;32m    686\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    687\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    688\u001b[0m     (\n\u001b[0;32m    689\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfrom_numpy_matrix is deprecated and will be removed in NetworkX 3.0.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[39mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m    693\u001b[0m )\n\u001b[1;32m--> 694\u001b[0m \u001b[39mreturn\u001b[39;00m from_numpy_array(A, parallel_edges\u001b[39m=\u001b[39;49mparallel_edges, create_using\u001b[39m=\u001b[39;49mcreate_using)\n",
      "File \u001b[1;32mc:\\Users\\rdutr\\anaconda3\\envs\\mscenv\\lib\\site-packages\\networkx\\convert_matrix.py:1672\u001b[0m, in \u001b[0;36mfrom_numpy_array\u001b[1;34m(A, parallel_edges, create_using)\u001b[0m\n\u001b[0;32m   1670\u001b[0m \u001b[39mif\u001b[39;00m G\u001b[39m.\u001b[39mis_multigraph() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m G\u001b[39m.\u001b[39mis_directed():\n\u001b[0;32m   1671\u001b[0m     triples \u001b[39m=\u001b[39m ((u, v, d) \u001b[39mfor\u001b[39;00m u, v, d \u001b[39min\u001b[39;00m triples \u001b[39mif\u001b[39;00m u \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m v)\n\u001b[1;32m-> 1672\u001b[0m G\u001b[39m.\u001b[39;49madd_edges_from(triples)\n\u001b[0;32m   1673\u001b[0m \u001b[39mreturn\u001b[39;00m G\n",
      "File \u001b[1;32mc:\\Users\\rdutr\\anaconda3\\envs\\mscenv\\lib\\site-packages\\networkx\\classes\\graph.py:946\u001b[0m, in \u001b[0;36mGraph.add_edges_from\u001b[1;34m(self, ebunch_to_add, **attr)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd_edges_from\u001b[39m(\u001b[39mself\u001b[39m, ebunch_to_add, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mattr):\n\u001b[0;32m    909\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Add all the edges in ebunch_to_add.\u001b[39;00m\n\u001b[0;32m    910\u001b[0m \n\u001b[0;32m    911\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[39m    >>> G.add_edges_from([(3, 4), (1, 4)], label=\"WN2898\")\u001b[39;00m\n\u001b[0;32m    945\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 946\u001b[0m     \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m ebunch_to_add:\n\u001b[0;32m    947\u001b[0m         ne \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(e)\n\u001b[0;32m    948\u001b[0m         \u001b[39mif\u001b[39;00m ne \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\rdutr\\anaconda3\\envs\\mscenv\\lib\\site-packages\\networkx\\convert_matrix.py:1661\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1657\u001b[0m     triples \u001b[39m=\u001b[39m chain(\n\u001b[0;32m   1658\u001b[0m         ((u, v, {\u001b[39m\"\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m}) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(A[u, v])) \u001b[39mfor\u001b[39;00m (u, v) \u001b[39min\u001b[39;00m edges\n\u001b[0;32m   1659\u001b[0m     )\n\u001b[0;32m   1660\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# basic data type\u001b[39;00m\n\u001b[1;32m-> 1661\u001b[0m     triples \u001b[39m=\u001b[39m ((u, v, \u001b[39mdict\u001b[39m(weight\u001b[39m=\u001b[39mpython_type(A[u, v]))) \u001b[39mfor\u001b[39;00m u, v \u001b[39min\u001b[39;00m edges)\n\u001b[0;32m   1662\u001b[0m \u001b[39m# If we are creating an undirected multigraph, only add the edges from the\u001b[39;00m\n\u001b[0;32m   1663\u001b[0m \u001b[39m# upper triangle of the matrix. Otherwise, add all the edges. This relies\u001b[39;00m\n\u001b[0;32m   1664\u001b[0m \u001b[39m# on the fact that the vertices created in the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1668\u001b[0m \u001b[39m# Without this check, we run into a problem where each edge is added twice\u001b[39;00m\n\u001b[0;32m   1669\u001b[0m \u001b[39m# when `G.add_edges_from()` is invoked below.\u001b[39;00m\n\u001b[0;32m   1670\u001b[0m \u001b[39mif\u001b[39;00m G\u001b[39m.\u001b[39mis_multigraph() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m G\u001b[39m.\u001b[39mis_directed():\n",
      "File \u001b[1;32mc:\\Users\\rdutr\\anaconda3\\envs\\mscenv\\lib\\site-packages\\networkx\\convert_matrix.py:1626\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1623\u001b[0m G\u001b[39m.\u001b[39madd_nodes_from(\u001b[39mrange\u001b[39m(n))\n\u001b[0;32m   1624\u001b[0m \u001b[39m# Get a list of all the entries in the array with nonzero entries. These\u001b[39;00m\n\u001b[0;32m   1625\u001b[0m \u001b[39m# coordinates become edges in the graph. (convert to int from np.int64)\u001b[39;00m\n\u001b[1;32m-> 1626\u001b[0m edges \u001b[39m=\u001b[39m ((\u001b[39mint\u001b[39m(e[\u001b[39m0\u001b[39;49m]), \u001b[39mint\u001b[39m(e[\u001b[39m1\u001b[39m])) \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mA\u001b[39m.\u001b[39mnonzero()))\n\u001b[0;32m   1627\u001b[0m \u001b[39m# handle numpy constructed data type\u001b[39;00m\n\u001b[0;32m   1628\u001b[0m \u001b[39mif\u001b[39;00m python_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvoid\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1629\u001b[0m     \u001b[39m# Sort the fields by their offset, then by dtype, then by name.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "problematic_execs=[]\n",
    "for dataset in tqdm(['ml-100k', 'jester'], desc='General Progress', leave=True):\n",
    "    data = Dataset.load_builtin(dataset)\n",
    "    for test_size in tqdm([0.25, 0.1, 0.01], desc='Test Size Progress', leave=False):\n",
    "        shuffle_split = ShuffleSplit(n_splits=100, test_size=test_size)\n",
    "        split_id = 1\n",
    "        for trainset, testset in tqdm(shuffle_split.split(data), desc='Splits Progress', leave=False): \n",
    "            for similarity_metric in  tqdm(['euclidean', 'cosine', 'l1', 'l2'], desc='Similarity Metric Progress', leave=False): \n",
    "                for detector_name, community_detector in tqdm(communities_detectors.items(), desc='Community Detector Progress', leave=False):\n",
    "                    for algo_name, algo in  tqdm(algos_recommendation.items(), desc='Algorithm Progress', leave=False):            \n",
    "                        if community_detector != None:\n",
    "                            trainpd, testpd = uncouple(trainset, testset)\n",
    "                            similarity_matrix = get_similarity_matrix(trainpd, index=['uid'], columns=['iid'], \n",
    "                                                                    values='rating', metric=similarity_metric)\n",
    "                            G = nx.from_numpy_matrix(similarity_matrix)\n",
    "                            for u, v in G.edges():\n",
    "                                similarity = similarity_matrix[u][v]\n",
    "                                G[u][v]['weight'] = similarity\n",
    "                            if communities_detectors == 'Paris':\n",
    "                                try:\n",
    "                                    coms = community_detector(G)\n",
    "                                except Exception as e:\n",
    "                                    problematic_execs.append([\n",
    "                                        'Problem with communiy detection', dataset, similarity_metric, \n",
    "                                        detector_name, algo_name, test_size, split_id\n",
    "                                    ])\n",
    "                                continue\n",
    "                            else:\n",
    "                                try:\n",
    "                                    coms = community_detector(G, weights='weight')\n",
    "                                except Exception as e:\n",
    "                                    problematic_execs.append([\n",
    "                                        'communiy detection', dataset, similarity_metric, \n",
    "                                        detector_name, algo_name, test_size, split_id\n",
    "                                    ])\n",
    "                                continue\n",
    "                            all_predictions = []\n",
    "                            for community in tqdm(coms.communities, desc='Communities progress', leave=False):\n",
    "                                train_community = trainpd[trainpd['uid'].isin(community)]\n",
    "                                test_community = testpd[testpd['uid'].isin([str(x) for x in community])]\n",
    "                                \n",
    "                                reader = Reader(rating_scale=(1, 5))\n",
    "                                train_surprise = Dataset.load_from_df(train_community[['uid', 'iid', 'rating']], \n",
    "                                                                        reader)\n",
    "                                train_surprise = train_surprise.build_full_trainset()\n",
    "                                test_surprise = list(test_community.itertuples(index=False, name=None))\n",
    "                                \n",
    "                                try:\n",
    "                                    algo.fit(train_surprise)\n",
    "                                except Exception as e:\n",
    "                                    problematic_execs.append([\n",
    "                                        'model fitting', dataset, similarity_metric, \n",
    "                                        detector_name, algo_name, test_size, split_id\n",
    "                                    ])\n",
    "                                continue\n",
    "                                try:    \n",
    "                                    predictions = algo.test(test_surprise)\n",
    "                                except Exception as e:\n",
    "                                    problematic_execs.append([\n",
    "                                        'model prediction', dataset, similarity_metric, \n",
    "                                        detector_name, algo_name, test_size, split_id\n",
    "                                    ])\n",
    "                                continue      \n",
    "                                all_predictions.extend(predictions)\n",
    "                            rmse_value = accuracy.rmse(all_predictions, verbose=False)\n",
    "                            mse_value = accuracy.mse(all_predictions, verbose=False)\n",
    "                            mae_value = accuracy.mae(all_predictions, verbose=False)\n",
    "                        else:\n",
    "                            try:\n",
    "                                algo.fit(trainset)\n",
    "                            except Exception as e:\n",
    "                                    problematic_execs.append([\n",
    "                                        'model fitting', dataset, similarity_metric, \n",
    "                                        detector_name, algo_name, test_size, split_id\n",
    "                                    ])\n",
    "                            continue\n",
    "                            try:\n",
    "                                predictions = algo.test(testset)\n",
    "                            except Exception as e:\n",
    "                                    problematic_execs.append([\n",
    "                                        'model prediction', dataset, similarity_metric, \n",
    "                                        detector_name, algo_name, test_size, split_id\n",
    "                                    ])\n",
    "                            continue\n",
    "                        rmse_value = accuracy.rmse(predictions, verbose=False)\n",
    "                        mse_value = accuracy.mse(predictions, verbose=False)\n",
    "                        mae_value = accuracy.mae(predictions, verbose=False)\n",
    "                        result_dict = {\n",
    "                            'dataset': dataset,\n",
    "                            'similarity_metric': similarity_metric,\n",
    "                            'community_detector': detector_name,\n",
    "                            'algorithm_rec': algo_name,\n",
    "                            'test_size': test_size,\n",
    "                            'split_id': split_id,\n",
    "                            'rmse': rmse_value,\n",
    "                            'mse': mse_value,\n",
    "                            'mae': mae_value\n",
    "                        }\n",
    "                        results.append(result_dict)\n",
    "                        split_id += 1\n",
    "\n",
    "\n",
    "# Saving results as .csv file\n",
    "df_results = pd.DataFrame(results)\n",
    "file_name = 'results.csv'\n",
    "notebook_dir = os.getcwd()\n",
    "outputs_dir = notebook_dir.replace('notebooks', 'outputs')\n",
    "file_path = os.path.join(outputs_dir, file_name)\n",
    "df_results.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_execs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mscenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9af17dd3974b7d3f07030b1611a67048f1f5084e02d6dc9f5527477bb4d7d2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
